import re
import markdown
import html2text
from flask import Blueprint, request, jsonify
from firebase_admin import firestore

# Import shared utility functions
from utils import extract_text, delete_collection, split_chunks
import redis

# --- BLUEPRINT SETUP ---
# Create a blueprint for study hub features
study_hub_bp = Blueprint('study_hub_bp', __name__)

# Global variables to hold dependencies injected from app.py
db = None
note_gen_model = None
chat_model = None
redis_client = None 

def set_dependencies(db_instance, note_model_instance, chat_model_instance, redis_instance):
    """Injects database and AI model dependencies from the main app."""
    global db, note_gen_model, chat_model, redis_client
    db = db_instance
    note_gen_model = note_model_instance
    chat_model = chat_model_instance
    print("‚úÖ Study Hub dependencies injected.")
    redis_client = redis_instance

# --- HELPER FUNCTIONS for Study Hub ---
def get_original_text(project_id, source_id):
    """Fetches and reassembles the original, unprocessed text for a specific source."""
    print(f"  üìö Retrieving original text for source {source_id} in project {project_id}...")
    full_text = ""
    source_ref = db.collection('projects').document(project_id).collection('sources').document(source_id)
    chunks_query = source_ref.collection('chunks').order_by('order').stream()
    
    all_chunks = []
    for chunk_page in chunks_query:
        all_chunks.extend(chunk_page.to_dict().get('chunks', []))
    
    full_text = "\n".join(all_chunks) # Join the chunks back into a single text block
    print(f"  ‚úÖ Assembled {len(full_text)} characters of original text.")
    return full_text

def generate_note(text):
    """Generates a simplified study note using the injected AI model."""
    print("  ü§ñ Generating AI study note...")
    prompt = f"""
    You are an expert academic study assistant. Your mission is to transform dense academic texts into simplified, well-structured study notes that are easy to understand, while strictly preserving the original document's structure.

    Your output must be in the **same language as the source text**. Follow these rules meticulously.

    **0. üèõÔ∏è The Golden Rule: Preserve the Original Structure**
    *   This is your most important command. You MUST follow the structure, headings, and topic order of the original text EXACTLY.
    *   Do not merge sections, re-order paragraphs, or write new introductory paragraphs. Your task is to simplify the content *within* each original section.

    **1. üí° The Simplification Rule: Clarify In-Place**
    *   Replace complex, technical, or academic words with simpler, more common equivalents in the same language.
    *   Break down long, complex sentences into shorter, clearer ones.

    **2. ‚úçÔ∏è The Annotation Rule: Translate Simplified Words**
    *   For **every single word** that you simplified, you MUST provide its Chinese translation immediately after.
    *   Format: `new simplified word (‰∏≠ÊñáÁøªËØë)`. Example: "The **widespread (ÊôÆÈÅçÁöÑ)** nature of the **event (‰∫ã‰ª∂)**..."

    **3. üé® The Formatting & Tone Rule: Be Clear and Direct**
    *   Use markdown headings (`#`, `##`) that match the original text's structure. Add a relevant emoji to each main heading.
    *   Use **bold text** to emphasize key simplified concepts.
    *   Adopt a clear, direct, and helpful academic tone.

    **4. üéØ The Content Rule: Be Comprehensive and Accurate**
    *   Cover all major topics and key concepts from the original text. Do not skip sections.
    *   Extract only the most critical information‚Äîdefinitions, key arguments, and essential examples.

    **5. üß† The Memory Aid Rule: Add a Mnemonic Tip (ËÆ∞ÂøÜÊäÄÂ∑ß)**
    *   At the end of each major section, create a short, creative Mnemonic Tip (ËÆ∞ÂøÜÊäÄÂ∑ß) to help recall the main points.

    **Constraint:**
    *   You must not add any new information that is not present in the original text.

    Here is the text to process:
    ---
    {text}
    ---
    """
    try:
        # Use the injected note_gen_model
        response = note_gen_model.generate_content(prompt)
        return markdown.markdown(response.text)
    except Exception as e:
        print(f"  ‚ùå Note generation failed: {e}")
        raise

def get_simplified_note_context(project_id, source_id=None):
    """Fetches and combines all simplified note pages into clean text for the chatbot."""
    print(f"  üìö Retrieving simplified note context for project {project_id}...")
    full_html_content = ""
    sources_to_query = []

    if source_id:
        source_ref = db.collection('projects').document(project_id).collection('sources').document(source_id)
        sources_to_query.append(source_ref)
    else:
        sources_stream = db.collection('projects').document(project_id).collection('sources').stream()
        sources_to_query = [source.reference for source in sources_stream]

    for source_ref in sources_to_query:
        pages_query = source_ref.collection('note_pages').order_by('order').stream()
        for page in pages_query:
            full_html_content += page.to_dict().get('html', '')

    if not full_html_content:
        print("  ‚ö†Ô∏è No note content found.")
        return ""

    # Convert HTML back to clean text for the AI model
    h = html2text.HTML2Text()
    h.ignore_links = True
    h.ignore_images = True
    clean_text = h.handle(full_html_content)
    
    print(f"  ‚úÖ Assembled {len(clean_text)} characters of simplified note text.")
    return clean_text

# --- ROUTES ---

@study_hub_bp.route('/get-projects', methods=['GET'])
def get_projects():
    docs = db.collection('projects').order_by('timestamp', direction=firestore.Query.DESCENDING).stream()
    projects = [{"id": d.id, "name": d.to_dict().get('name')} for d in docs]
    return jsonify(projects)

# In create_project function
@study_hub_bp.route('/create-project', methods=['POST'])
def create_project():
    name = request.json.get('name')
    user_id = get_current_user_id() # Assuming this gets the user's UID
    if not user_id:
        return jsonify({"error": "Authentication required"}), 401
    
    ref = db.collection('projects').document()
    ref.set({
        'name': name,
        'timestamp': firestore.SERVER_TIMESTAMP,
        'userId': user_id  
    })
    return jsonify({"id": ref.id})

@study_hub_bp.route('/rename-project/<project_id>', methods=['PUT'])
def rename_project(project_id):
    new_name = request.json.get('new_name')
    if not new_name:
        return jsonify({"success": False, "error": "New name not provided"}), 400
    try:
        project_ref = db.collection('projects').document(project_id)
        project_ref.update({'name': new_name})
        return jsonify({"success": True, "message": f"Project renamed to {new_name}."}), 200
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@study_hub_bp.route('/delete-project/<project_id>', methods=['DELETE'])
def delete_project(project_id):
    print(f"\nüóëÔ∏è  DELETE REQUEST for project: {project_id}")
    try:
        project_ref = db.collection('projects').document(project_id)
        for collection_ref in project_ref.collections():
            delete_collection(collection_ref, batch_size=50)
        project_ref.delete()
        print(f"‚úÖ Successfully deleted project: {project_id}")
        return jsonify({"success": True}), 200
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@study_hub_bp.route('/get-sources/<project_id>', methods=['GET'])
def get_sources(project_id):
    docs = db.collection('projects').document(project_id).collection('sources').stream()
    sources = [{"id": d.id, "filename": d.to_dict().get('filename')} for d in docs]
    return jsonify(sources)

@study_hub_bp.route('/upload-source/<project_id>', methods=['POST'])
def upload_source(project_id):
    print(f"\nüìÅ UPLOAD REQUEST for project: {project_id}")
    if 'pdfs' not in request.files:
        return jsonify({"error": "No files provided", "success": False}), 400
    
    files = request.files.getlist('pdfs')
    if not files or files[0].filename == '':
        return jsonify({"error": "No files selected", "success": False}), 400
    
    processed, errors = [], []
    for file in files:
        filename = file.filename
        safe_id = re.sub(r'[.#$/[\]]', '_', filename) # Make filename Firestore-safe
        print(f"\nüîÑ Processing '{filename}'...")
        try:
            file.stream.seek(0)
            text = extract_text(file.stream)
            if not text.strip():
                errors.append({"filename": filename, "error": "No text could be extracted."})
                continue

            source_ref = db.collection('projects').document(project_id).collection('sources').document(safe_id)
            source_ref.set({'filename': filename, 'timestamp': firestore.SERVER_TIMESTAMP, 'character_count': len(text)})
            
            note_html = generate_note(text)
            
            # Save note in chunks to avoid Firestore document size limits
            chunk_size = 900000 
            for i in range(0, len(note_html), chunk_size):
                chunk = note_html[i:i+chunk_size]
                page_num = i // chunk_size
                source_ref.collection('note_pages').document(f'page_{page_num}').set({'html': chunk, 'order': page_num})
            
            # Save original text chunks for context-aware features
            text_chunks = split_chunks(text)
            for i in range(0, len(text_chunks), 100):
                batch = text_chunks[i:i+100]
                page_num = i // 100
                source_ref.collection('chunks').document(f'page_{page_num}').set({'chunks': batch, 'order': page_num})
            
            processed.append({"filename": filename, "id": safe_id})
            print(f"‚úÖ SUCCESS: '{filename}' processed.")
        except Exception as e:
            import traceback
            print(f"‚ùå CRITICAL ERROR processing '{filename}': {e}")
            traceback.print_exc()
            errors.append({"filename": filename, "error": str(e)})

    return jsonify({"success": len(processed) > 0, "processed": processed, "errors": errors})

@study_hub_bp.route('/delete-source/<project_id>/<path:source_id>', methods=['DELETE'])
def delete_source(project_id, source_id):
    print(f"\nüóëÔ∏è  DELETE REQUEST for source: {source_id}")
    try:
        source_ref = db.collection('projects').document(project_id).collection('sources').document(source_id)
        for collection_ref in source_ref.collections():
            delete_collection(collection_ref, batch_size=50)
        source_ref.delete()

        if redis_client:
            try:
                note_redis_key = f"note:{project_id}:{source_id}"
                redis_client.delete(note_redis_key)
                print(f"‚úÖ Invalidated Redis cache for deleted source: {note_redis_key}")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to invalidate note cache for deleted source: {e}")

        print(f"‚úÖ Successfully deleted source document: {source_id}")
        return jsonify({"success": True, "message": f"Source {source_id} deleted."}), 200

    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@study_hub_bp.route('/get-note/<project_id>/<path:source_id>', methods=['GET'])
def get_note(project_id, source_id):
    note_redis_key = f"note:{project_id}:{source_id}"

    if redis_client:
        try:
            cached_html_bytes = redis_client.get(note_redis_key)
            if cached_html_bytes:
                print(f"‚úÖ CACHE HIT for note: {note_redis_key}")
                # --- THIS IS THE FIX ---
                # Decode the bytes from Redis into a UTF-8 string.
                return jsonify({"note_html": cached_html_bytes.decode('utf-8')})
                # --- END OF FIX ---
        except Exception as e:
            print(f"‚ö†Ô∏è Redis cache check failed for note: {e}")

    print(f"CACHE MISS for note: {note_redis_key}. Fetching from Firestore...")

    # 2. If miss, get from Firestore
    try:
        pages_query = db.collection('projects').document(project_id) \
                      .collection('sources').document(source_id) \
                      .collection('note_pages').order_by('order').stream()
        
        html = "".join(p.to_dict().get('html', '') for p in pages_query)
        
        # 3. Store the assembled HTML in Redis for next time
        if redis_client and html:
            try:
                # Cache for 1 hour (3600 seconds)
                redis_client.setex(note_redis_key, 3600, html)
                print(f"üíæ Successfully stored note in Redis cache: {note_redis_key}")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to store note in Redis cache: {e}")

        return jsonify({"note_html": html or "<p>No note generated yet.</p>"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@study_hub_bp.route('/update-note/<project_id>/<path:source_id>', methods=['POST'])
def update_note(project_id, source_id):
    new_html = request.json.get('html_content')
    if new_html is None:
        return jsonify({"error": "Missing 'html_content'"}), 400
    try:
        source_ref = db.collection('projects').document(project_id).collection('sources').document(source_id)
        note_pages_ref = source_ref.collection('note_pages')
        
        # Delete old pages
        for doc in note_pages_ref.stream():
            doc.reference.delete()
        
        # Save new content in chunks
        chunk_size = 900000
        for i in range(0, len(new_html), chunk_size):
            chunk = new_html[i:i+chunk_size]
            page_num = i // chunk_size
            
            note_pages_ref.document(f'page_{page_num}').set({
                'html': chunk,
                'order': page_num
            })
            note_pages_saved += 1
            print(f"  + Saving new note page {page_num}")

        if redis_client:
            try:
                note_redis_key = f"note:{project_id}:{source_id}"
                redis_client.delete(note_redis_key)
                print(f"‚úÖ Invalidated Redis cache for note: {note_redis_key}")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to invalidate note cache: {e}")
        
        print(f"‚úÖ Note updated successfully. {note_pages_saved} pages saved.")
        return jsonify({"success": True, "message": "Note updated successfully"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@study_hub_bp.route('/ask-chatbot/<project_id>', methods=['POST'])
def ask_chatbot(project_id):
    data = request.json
    question = data.get('question')
    source_id = data.get('source_id') # Can be a specific source ID or null for 'all'
    
    context = get_simplified_note_context(project_id, source_id)
    if not context:
        return jsonify({"answer": "I couldn't find any generated notes to read. Please upload a document first!"})

    prompt = f"You are a helpful study assistant. Answer the user's question based *only* on the provided study notes. The notes are simplified summaries, so be concise. If the answer is not in the notes, say 'I'm sorry, that information isn't in my simplified notes.'\n\nStudy Notes:\n---\n{context}\n---\n\nQuestion: {question}\n\nAnswer:"
    
    try:
        # Use the injected chat_model
        answer = chat_model.generate_content(prompt).text
        return jsonify({"answer": answer})
    except Exception as e:
        return jsonify({"answer": f"Sorry, an error occurred: {e}"})

@study_hub_bp.route('/generate-topic-note/<project_id>', methods=['POST'])
def topic_note(project_id):
    topic = request.json.get('topic')
    print(f"  üîç Extracting topic '{topic}' from simplified notes...")

    simplified_notes_context = get_simplified_note_context(project_id)
    if not simplified_notes_context:
        return jsonify({"note_html": "<p>Could not find any notes to search through.</p>"})

    prompt = f"""
    You are an information retrieval assistant. Your task is to act like a "smart search".
    Given a TOPIC and existing STUDY NOTES, find and extract all sections, headings, paragraphs, and bullet points from the STUDY NOTES that are relevant to the TOPIC.

    RULES:
    1.  EXTRACT ONLY: Do NOT write new sentences or summaries. Your output must be a direct copy of relevant parts from the notes.
    2.  PRESERVE FORMATTING: Keep the original markdown formatting (headings, bold text, etc.).
    3.  NO COMMENTARY: Do not add text like "Here are the relevant sections...". Start immediately with the first extracted piece of content. If nothing is found, return only: "I could not find any information about that topic in the notes."

    ---
    TOPIC: {topic}
    ---
    EXISTING STUDY NOTES:
    {simplified_notes_context}
    ---
    """
    
    try:
        response_text = note_gen_model.generate_content(prompt).text
        html = markdown.markdown(response_text)
        return jsonify({"note_html": html})
    except Exception as e:
        return jsonify({"note_html": f"<p>Error generating topic note: {e}</p>"})
    
@study_hub_bp.route('/regenerate-note/<project_id>/<path:source_id>', methods=['POST'])
def regenerate_note(project_id, source_id):
    """Regenerates the simplified note for a single source and returns the new HTML."""
    print(f"\nüîÑ REGENERATE NOTE request for source: {source_id} in project: {project_id}")
    try:
        # 1. Get the original text from Firestore
        original_text = get_original_text(project_id, source_id)
        if not original_text:
            return jsonify({"error": "Original source text not found or is empty."}), 404

        # 2. Generate the new note using the same function as upload
        new_note_html = generate_note(original_text)
        
        # 3. Overwrite the old note pages in Firestore
        source_ref = db.collection('projects').document(project_id).collection('sources').document(source_id)
        note_pages_ref = source_ref.collection('note_pages')
        
        # Delete old pages first for a clean slate
        for doc in note_pages_ref.stream():
            doc.reference.delete()
            
        # Save new content in chunks
        chunk_size = 900000 
        for i, chunk in enumerate(range(0, len(new_note_html), chunk_size)):
            page_content = new_note_html[chunk:chunk + chunk_size]
            note_pages_ref.document(f'page_{i}').set({'html': page_content, 'order': i})

        # 4. Invalidate the Redis cache for this specific note
        if redis_client:
            note_redis_key = f"note:{project_id}:{source_id}"
            redis_client.delete(note_redis_key)
            print(f"  ‚úÖ Invalidated Redis cache for regenerated note: {note_redis_key}")

        print(f"  ‚úÖ SUCCESS: Note for '{source_id}' regenerated.")
        # 5. Return the new HTML directly to the frontend
        return jsonify({"success": True, "note_html": new_note_html})

    except Exception as e:
        import traceback
        print(f"‚ùå CRITICAL ERROR regenerating note '{source_id}': {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500